{
  "cells": [
    {
      "source": [
        "import kagglehub\n",
        "andrewmvd_road_sign_detection_path = kagglehub.dataset_download('andrewmvd/road-sign-detection')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "XafsXEibeV-H",
        "outputId": "c046ae6c-0781-418c-c179-89ad978ebd1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/andrewmvd/road-sign-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 218M/218M [00:02<00:00, 86.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "metadata": {
        "id": "d6fCAd-teV-O"
      },
      "cell_type": "markdown",
      "source": [
        "# Road Traffic Signs - Bounding Box Predictions"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "TbsbfThaeV-X"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import random\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8nsUECJHeV-Z"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "XCQbcx-TeV-b"
      },
      "cell_type": "code",
      "source": [
        "base_path = '../input/road-sign-detection/'\n",
        "ann_path = base_path + 'annotations/'\n",
        "img_path = base_path + 'images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4DvHKHD8eV-d"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare the Training Dataframe"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "h0xqR1bueV-f"
      },
      "cell_type": "code",
      "source": [
        "def get_file_list(root, file_type):\n",
        "    return [os.path.join(directory_path, f) for directory_path, directory_name,\n",
        "            files in os.walk(root) for f in files if f.endswith(file_type)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "--brnyxTeV-i"
      },
      "cell_type": "code",
      "source": [
        "def get_train_df(ann_path, img_path):\n",
        "    ann_path_list = get_file_list(ann_path, '.xml')\n",
        "    ann_list = []\n",
        "    for a_path in ann_path_list:\n",
        "        root = ET.parse(a_path).getroot()\n",
        "        ann = {}\n",
        "        ann['filename'] = Path(str(img_path) + '/'+ root.find(\"./filename\").text)\n",
        "        ann['width'] = root.find(\"./size/width\").text\n",
        "        ann['height'] = root.find(\"./size/height\").text\n",
        "        ann['class'] = root.find(\"./object/name\").text\n",
        "        ann['xmin'] = int(root.find(\"./object/bndbox/xmin\").text)\n",
        "        ann['ymin'] = int(root.find(\"./object/bndbox/ymin\").text)\n",
        "        ann['xmax'] = int(root.find(\"./object/bndbox/xmax\").text)\n",
        "        ann['ymax'] = int(root.find(\"./object/bndbox/ymax\").text)\n",
        "        ann_list.append(ann)\n",
        "    return pd.DataFrame(ann_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zFJ3G4TveV-k"
      },
      "cell_type": "code",
      "source": [
        "df_train = get_train_df(ann_path, img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RRwwqqF9eV-n"
      },
      "cell_type": "code",
      "source": [
        "class_dict = {'speedlimit': 0, 'stop': 1, 'crosswalk': 2, 'trafficlight': 3}\n",
        "idx_to_class = {k:v for k,v in enumerate(list(class_dict.keys()))}\n",
        "df_train['class'] = df_train['class'].apply(lambda x:  class_dict[x])\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qviL8zqeV-q"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare Images size and bounding boxes"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "NwGdH_vVeV-s"
      },
      "cell_type": "code",
      "source": [
        "# additional functions\n",
        "\n",
        "def read_image(path):\n",
        "    return cv2.cvtColor(cv2.imread(str(path)), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "def create_bb_array(x):\n",
        "    return np.array([x[5],x[4],x[7],x[6]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hSb75UbSeV-v"
      },
      "cell_type": "code",
      "source": [
        "# masks functions\n",
        "\n",
        "def create_mask(bb, x):\n",
        "    rows,cols,*_ = x.shape\n",
        "    Y = np.zeros((rows, cols))\n",
        "    bb = bb.astype(np.int)\n",
        "    Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n",
        "    return Y\n",
        "\n",
        "def mask_to_bb(Y):\n",
        "    cols, rows = np.nonzero(Y)\n",
        "    if len(cols)==0:\n",
        "        return np.zeros(4, dtype=np.float32)\n",
        "    top_row = np.min(rows)\n",
        "    left_col = np.min(cols)\n",
        "    bottom_row = np.max(rows)\n",
        "    right_col = np.max(cols)\n",
        "    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vv93YKfCeV-0"
      },
      "cell_type": "code",
      "source": [
        "def resize_image_bb(read_path, write_path, bb, sz):\n",
        "    im = read_image(read_path)\n",
        "    im_resized = cv2.resize(im, (int(1.49*sz), sz))\n",
        "    Y_resized = cv2.resize(create_mask(bb, im), (int(1.49*sz), sz))\n",
        "    new_path = str(write_path/read_path.parts[-1])\n",
        "    cv2.imwrite(new_path, cv2.cvtColor(im_resized, cv2.COLOR_RGB2BGR))\n",
        "    return new_path, mask_to_bb(Y_resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xUgDcd9OeV-2"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf images_resized\n",
        "!mkdir images_resized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4JYqJ0QueV-4"
      },
      "cell_type": "code",
      "source": [
        "new_paths = []\n",
        "new_bbs = []\n",
        "train_path_resized = Path('images_resized')\n",
        "\n",
        "for index, row in df_train.iterrows():\n",
        "    new_path,new_bb = resize_image_bb(row['filename'], train_path_resized, create_bb_array(row.values),300)\n",
        "    new_paths.append(new_path)\n",
        "    new_bbs.append(new_bb)\n",
        "\n",
        "df_train['new_path'] = new_paths\n",
        "df_train['new_bb'] = new_bbs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwDyU8WkeV-5"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-_MIqAh9eV-6"
      },
      "cell_type": "code",
      "source": [
        "# crop functions\n",
        "\n",
        "def crop(im, r, c, target_r, target_c):\n",
        "    return im[r:r+target_r, c:c+target_c]\n",
        "\n",
        "def random_crop(x, r_pix=8):\n",
        "    r, c,*_ = x.shape\n",
        "    c_pix = round(r_pix*c/r)\n",
        "    rand_r = random.uniform(0, 1)\n",
        "    rand_c = random.uniform(0, 1)\n",
        "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
        "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
        "    return crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
        "\n",
        "def center_crop(x, r_pix=8):\n",
        "    r, c,*_ = x.shape\n",
        "    c_pix = round(r_pix*c/r)\n",
        "    return crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n",
        "\n",
        "def random_cropXY(x, Y, r_pix=8):\n",
        "    r, c,*_ = x.shape\n",
        "    c_pix = round(r_pix*c/r)\n",
        "    rand_r = random.uniform(0, 1)\n",
        "    rand_c = random.uniform(0, 1)\n",
        "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
        "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
        "    xx = crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
        "    YY = crop(Y, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
        "    return xx, YY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3mDepIaLeV-8"
      },
      "cell_type": "code",
      "source": [
        "def rotate_cv(im, deg, y=False, mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
        "    \"\"\" Rotates an image by deg degrees\"\"\"\n",
        "    r,c,*_ = im.shape\n",
        "    M = cv2.getRotationMatrix2D((c/2,r/2),deg,1)\n",
        "    if y:\n",
        "        return cv2.warpAffine(im, M,(c,r), borderMode=cv2.BORDER_CONSTANT)\n",
        "    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wW600W2qeV-_"
      },
      "cell_type": "code",
      "source": [
        "# main function for augmentation\n",
        "\n",
        "def transformsXY(path, bb, transforms):\n",
        "    x = cv2.imread(str(path)).astype(np.float32)\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)/255\n",
        "    Y = create_mask(bb, x)\n",
        "    if transforms:\n",
        "        rdeg = (np.random.random()-.50)*20\n",
        "        x = rotate_cv(x, rdeg)\n",
        "        Y = rotate_cv(Y, rdeg, y=True)\n",
        "        if np.random.random() > 0.5:\n",
        "            x = np.fliplr(x).copy()\n",
        "            Y = np.fliplr(Y).copy()\n",
        "        x, Y = random_cropXY(x, Y)\n",
        "    else:\n",
        "        x, Y = center_crop(x), center_crop(Y)\n",
        "    return x, mask_to_bb(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "027jBQHSeV_C"
      },
      "cell_type": "code",
      "source": [
        "# functions to create and show the boxes\n",
        "\n",
        "def create_corner_rect(bb, color='red'):\n",
        "    bb = np.array(bb, dtype=np.float32)\n",
        "    return plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color=color,\n",
        "                         fill=False, lw=3)\n",
        "\n",
        "def show_corner_bb(im, bb):\n",
        "    plt.imshow(im)\n",
        "    plt.gca().add_patch(create_corner_rect(bb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G3acOjteeV_E"
      },
      "cell_type": "markdown",
      "source": [
        "# Demo Image with Bounding Box"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rVOX9cFIeV_F"
      },
      "cell_type": "code",
      "source": [
        "# before transformation\n",
        "\n",
        "im = cv2.imread(str(df_train.values[100][8]))\n",
        "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "show_corner_bb(im, df_train.values[100][9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vsnmW9WEeV_G"
      },
      "cell_type": "code",
      "source": [
        "# after transformation\n",
        "\n",
        "im, bb = transformsXY(str(df_train.values[100][8]),df_train.values[100][9],True )\n",
        "show_corner_bb(im, bb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YomEkBsoeV_H"
      },
      "cell_type": "markdown",
      "source": [
        "# Split DataSet"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mb-aIuNueV_I"
      },
      "cell_type": "code",
      "source": [
        "df_train = df_train.reset_index()\n",
        "\n",
        "X = df_train[['new_path', 'new_bb']]\n",
        "y = df_train['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_EXi2FLCeV_J"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8zCRrnCeV_K"
      },
      "cell_type": "markdown",
      "source": [
        "# Road Traffic Signs Dataset"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "o7dD2NlGeV_L"
      },
      "cell_type": "code",
      "source": [
        "class RoadDataset(Dataset):\n",
        "    def __init__(self, paths, bb, y, transforms=False):\n",
        "        self.transforms = transforms\n",
        "        self.paths = paths.values\n",
        "        self.bb = bb.values\n",
        "        self.y = y.values\n",
        "\n",
        "    def normalize(self, im):\n",
        "        imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
        "        return (im - imagenet_stats[0])/imagenet_stats[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.paths[idx]\n",
        "        y_class = self.y[idx]\n",
        "        x, y_bb = transformsXY(path, self.bb[idx], self.transforms)\n",
        "        x = self.normalize(x)\n",
        "        x = np.rollaxis(x, 2)\n",
        "        return x, y_class, y_bb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "F_a8RuyVeV_M"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_ds = RoadDataset(X_train['new_path'],X_train['new_bb'] ,y_train, transforms=True)\n",
        "valid_ds = RoadDataset(X_test['new_path'],X_test['new_bb'],y_test)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCyJ6LfEeV_N"
      },
      "cell_type": "markdown",
      "source": [
        "# Bounding Box Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8zftvLlpeV_O"
      },
      "cell_type": "code",
      "source": [
        "class BB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BB, self).__init__()\n",
        "        resnet = models.resnet34(pretrained=True)\n",
        "        layers = list(resnet.children())[:8]\n",
        "        self.features1 = nn.Sequential(*layers[:6])\n",
        "        self.features2 = nn.Sequential(*layers[6:])\n",
        "        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
        "        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features1(x)\n",
        "        x = self.features2(x)\n",
        "        x = F.relu(x)\n",
        "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        return self.classifier(x), self.bb(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KT43RisOeV_P"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "496ZIbQDeV_Q"
      },
      "cell_type": "code",
      "source": [
        "def update_optimizer(optimizer, lr):\n",
        "    for i, param_group in enumerate(optimizer.param_groups):\n",
        "        param_group[\"lr\"] = lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "p0no11IweV_U"
      },
      "cell_type": "code",
      "source": [
        "def train_epocs(model, optimizer, train_dl, val_dl, epochs=10,C=1000):\n",
        "    idx = 0\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        total = 0\n",
        "        sum_loss = 0\n",
        "        for x, y_class, y_bb in train_dl:\n",
        "            batch = y_class.shape[0]\n",
        "            x = x.cuda().float()\n",
        "            y_class = y_class.cuda()\n",
        "            y_bb = y_bb.cuda().float()\n",
        "            out_class, out_bb = model(x)\n",
        "            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
        "            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
        "            loss_bb = loss_bb.sum()\n",
        "            loss = loss_class + loss_bb/C\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            idx += 1\n",
        "            total += batch\n",
        "            sum_loss += loss.item()\n",
        "        train_loss = sum_loss/total\n",
        "        val_loss, val_acc = val_metrics(model, valid_dl, C)\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(\"i:%4d train_loss:%5.3f val_loss:%5.3f val_acc:%5.3f\" % ((i+1), train_loss, val_loss, val_acc))\n",
        "    return sum_loss/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YixvKaeCeV_V"
      },
      "cell_type": "code",
      "source": [
        "def val_metrics(model, valid_dl, C=1000):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    sum_loss = 0\n",
        "    correct = 0\n",
        "    for x, y_class, y_bb in valid_dl:\n",
        "        batch = y_class.shape[0]\n",
        "        x = x.cuda().float()\n",
        "        y_class = y_class.cuda()\n",
        "        y_bb = y_bb.cuda().float()\n",
        "        out_class, out_bb = model(x)\n",
        "        loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
        "        loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
        "        loss_bb = loss_bb.sum()\n",
        "        loss = loss_class + loss_bb/C\n",
        "        _, pred = torch.max(out_class, 1)\n",
        "        correct += pred.eq(y_class).sum().item()\n",
        "        sum_loss += loss.item()\n",
        "        total += batch\n",
        "    return sum_loss/total, correct/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vACuN7fXeV_X"
      },
      "cell_type": "code",
      "source": [
        "model = BB().cuda()\n",
        "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "optimizer = torch.optim.Adam(parameters, lr=0.002)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vAE5jqVceV_X"
      },
      "cell_type": "code",
      "source": [
        "train_epocs(model, optimizer, train_dl, valid_dl, epochs=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5hab6ui4eV_Y"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "jxr_DysXeV_9"
      },
      "cell_type": "code",
      "source": [
        "# Predict the first image of the validation set\n",
        "test_batch = next(iter(valid_dl))\n",
        "test_batch[0] = test_batch[0].type(torch.cuda.FloatTensor).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pAwcYcUEeV__"
      },
      "cell_type": "code",
      "source": [
        "out, bb = model(test_batch[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wiGBJ_4heWAC"
      },
      "cell_type": "code",
      "source": [
        "print('Class :', idx_to_class[torch.argmax(out[0]).item()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bdPFC9KpeWAH"
      },
      "cell_type": "code",
      "source": [
        "show_corner_bb(np.moveaxis(test_batch[0][0].cpu().numpy(), 0, 2), bb.detach().cpu().numpy().astype(int)[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Road Traffic Signs Bounding Box Prediction",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}